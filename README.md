# Stock-Market-Prediction
INTRODUCTION  

Stock return or stock market prediction is an important financial subject that has attracted researchers’ attention for many years. It involves an assumption that past publicly available information has some predictive relationship to future stock returns.

ALGORITHMS: -

For our project, we focused on two main algorithms for recommendations: Linear Regression and Random Forest.
Linear Regression: - To describe the linear association between quantitative variables, a statistical procedure called regression often is used to construct a model. Regression is used to assess the contribution of one or more “explanatory” variables (called independent variables) to one “response” (or dependent) variable. It also can be used to predict the value of one variable based on the values of others. When there is only one independent variable and when the relationship can be expressed as a straight line, the procedure is called simple linear regression.
Any straight line in two‐dimensional space can be represented by this equation:
y = a + bx
where y is the variable on the vertical axis, x is the variable on the horizontal axis, a is the y‐value where the line crosses the vertical axis (often called the intercept), and b is the amount of change in y corresponding to a one‐unit increase in x (often called the slope)

Random Forest Regressor: - A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decisiontrees. 
Random Forest has multiple decision trees as base learning models. We randomly perform row sampling and feature sampling from the dataset forming sample datasets for every model. This part is called Bootstrap.
